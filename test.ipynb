{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a30f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading DOCX file...\n",
      "[INFO] Loading skills and job titles...\n",
      "[INFO] Extracting skills and titles using spaCy...\n",
      "\n",
      "===== RESUME PARSE RESULT =====\n",
      "Top 500 Characters of Extracted Text:\n",
      " Velamala Pavan Krishna\n",
      "\n",
      "SUMMARY\n",
      "Passionate computer science and AI student with a strong foundation in machine learning, data analysis, and model building . Eager to explore emerging technologies and apply creative solutions to real-world problems . Committed to continuous learning, collaboration, and making a meaningful impact through AI.\n",
      "\n",
      "Phone:\n",
      "+91 7569637875\n",
      "Email:\n",
      "velamalapavankrishna@gmail.com\n",
      "Address: Visakhapatnam , \n",
      "Andhra Pradesh , India\n",
      "    530046\n",
      "\n",
      "Profile links\n",
      "\n",
      "Linkedin: linkedin.co \n",
      "\n",
      "Skills Found: ['Computer Science', 'CS', 'Using Python to Interact', 'Developers', 'javascript', 'Collaboration', 'AI Club', 'assembler', 'Python', 'computer science', 'Adaptive learning', 'MySQL', 'building', 'Email', 'HealthCare', 'ML', 'Mental health', 'AI Fundamentals', 'data analysis', 'CERTIFICATIONS', 'collaboration', 'css', 'Diabetes', 'scratch', 'Intelligence', 'AI & Development', 'Matlab', 'John Hopkins University', 'RISK', 'project', 'Iris', 'VScode', 'model building', 'Web', 'Library management', 'Fundamentals', 'Github', 'CSS', 'Git', 'Andhra Pradesh', 'PyTorch\\nMental', 'Models', 'management system', 'Critical Thinking', 'GPA', 'py', 'PhysioNet Challenge', 'Skills\\nTechnical', 'Javascript', 'Database', 'Web Development', 'Chess', 'RISK REDUCTION', 'Soft skills', 'DeepLearning', 'Data Structures', 'Microsoft', 'Algorithms', 'Mar', 'Google', 'foundation', 'health', 'Problem-Solving      Team Collaboration \\n Communication       Critical Thinking\\nFlexible Adaptive', 'Bus', 'Artificial Intelligence', 'machine learning', 'Proxy', 'AI', 'B-Tech', 'html', 'emerging technologies', 'prediction', 'ICTR-3 (INTERNATIONAL CONFERENCE ON TSUNAMI RISK REDUCTION& RESILIENCE', 'learning', 'HTML', 'Java', 'IBM', 'Python for Data Science', 'Data Science', 'C', 'Flask', 'Azure', 'java', 'Linkedin']\n",
      "Job Titles Found: ['assembler', 'student', 'classifier']\n",
      "[INFO] Converting PDF pages to images...\n",
      "[INFO] Running OCR on page 1\n",
      "[INFO] Running OCR on page 2\n",
      "[INFO] Running OCR on page 3\n",
      "[INFO] Running OCR on page 4\n",
      "[INFO] Loading skills and job titles...\n",
      "[INFO] Extracting skills and titles using spaCy...\n",
      "\n",
      "===== RESUME PARSE RESULT =====\n",
      "Top 500 Characters of Extracted Text:\n",
      " DIGVIJAYSINGHPARMAR\n",
      "\n",
      "Permanent Address: 40/C, Sangam Nagar, Indore, M.P â€” 452006\n",
      "Present Address:2195 NiralaKunj, Gas AthourityOf India Township\n",
      "Dibiyapur, Auraiya, Uttar Pradesh, |ndia-206244\n",
      "\n",
      "Emait:digv10sp@gmail.com, digvijay10sp@outlook.com\n",
      "Mobile: +91-9662489663\n",
      "\n",
      "in ee Jinkedin.com/in/digvijay-singh-parmar-aabb0953\n",
      "\n",
      "CAREER OBJECTIVE\n",
      "\n",
      "To utilize my ability and knowledge about Safety and Emergency control methods, including\n",
      "the detection of risks to prevent life-threatening harms and damages  \n",
      "\n",
      "Skills Found: ['PVT LTD', 'GAS', 'safety training', 'CERTIFICATIONS& EXTRA- CURICULLAR ACTIVITES', 'communication equipment', 'Water', 'SAP-PM & SAP-MM(such', 'IMS', 'Codes', 'training', 'SAP-PM & SAP-MM\\n\\n', 'protection systems', 'Marital Status: Married\\n\\nLanguages :', 'Fire Safety Audits', 'Oil and Gas', 'COLLAGE', 'Foam', 'd', 'Carryout', 'assessment', 'incident command', 'Running', 'Undergone 2D+3D Designing', 'organization', 'Fire & Safety', 'Training', 'prevention', 'plants', 'communications', 'availability', 'NBC Code', 'Rie', 'investigation', 'Fire Hydrant System', 'NiralaKunj', 'Velocity', 'Sit', 'Skype', 'TECHNOLOGY', 'HST', 'Suggest', 'Technology', 'working environment', 'CO2 Flooding', 'Dahej-Manufacturing Division', 'buildings', 'Swimming/Running/Chin-Up/Sit-Up/Push-Up', 'WORKING EXPERIENCE', 'ee', 'Preparation', 'protection', 'conducting', 'Fire protection', 'mobilization', 'firefighting', 'design', 'risk', 'Process Safety Management', 'Material', 'Safety training', 'Heat', 'waste', 'Mobile', 'operations', 'risk assessment', 'Develop/Evaluate', 'Maintain', 'fire safety', 'CO2', 'LTD', 'Semi Fixed Foam System', 'Velocity Water Spray System', 'prospect', 'Health', 'Spray', 'ISO', 'English', 'Fire Safety', 'fire protection', 'NEBOSH', 'water', 'Hindi\\n\\nPermanent Address', 'French', 'Uttar Pradesh', 'steps', 'SCHOOL', 'Firefighting', 'contro', 'Gaseous Flooding System', 'ISO-14001', 'Participate', 'master control', 'BOCW', 'Hindi', 'Health Safety at Work', 'IMS Internal Auditor Certificate', 'Conducting', 'OISD', 'EMS', 'NFPA\\nCodes', 'Present Address', 'reliability', 'NAGPUR', 'SAP', 'storage', 'NATIONAL\\nCIVIL DEFENCE COLLAGE', 'Status', 'DCP', 'command', 'Manufacturing', 'GOVT', 'preparation', 'disposal', 'x', 'ISO 14001 & 18001', 'Swimming', 'OHSAS-18001', 'on site', 'cooking', 'VERITAS', 'authorization', 'INDORE', 'Achieving Excellent Position', 'transportation', 'Reliance Physical Test Examination', 'oe', 'IPS', 'Hobbies', 'petrochemical', 'Hydrant System', 'high rise', 'completion', 'power plants', 'Smoke', 'Passport', 'NFPA', 'NATIONAL SAFETY COUNCIL', 'maintenance', 'ISO 14001', 'Gas Industry', 'contractors', 'statutes', 'record', 'modifications', 'award', 'B.E) Fire Technology', 'Fire and Safety', 'OFFICER - FIRE & SAFETY', 'Mig', 'QRA', 'smoke', 'Risk', 'internal audit', 'Birth', 'Oil', 'store', 'Process Safety', 'Rendering', 'ISO 9001', 'measures', 'Safe', 'Fire Safety Inspections & Audits/ Risk\\nAssessments', 'Safety & Loss', 'foam', 'OH&S', 'observation', 'IES IPS ACADEMY', 'HSE', 'Safety IES IPS ACADEMY', 'Purchase Requisitions & Material', 'mitigation', 'SAFETY ENGINEERING', 'Safety Training', 'Purchase Requisitions', 'testing', 'C', 'INDUSTRIAL SAFETY', 'Gas', 'RA', 'pear', 'Smoke & Heat Detection\\nSystem', 'VIJAYNAGAR INDORE Lette\\nPERSONALITY TRAIT', 'Requisitions', 'RELIANCE INDUSTRIES LIMITED', 'Government', 'PSM', 'Languages', 'preparedness', 'international standards', 'mock']\n",
      "Job Titles Found: ['Internal Auditor', 'SENIOR OFFICER', 'FIRE TECHNOLOGY & SAFETY ENGINEERING', 'Safety professional']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from docx import Document\n",
    "\n",
    "# Set your poppler and tesseract paths\n",
    "tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "poppler_path = r\"C:\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
    "pytesseract.pytesseract.tesseract_cmd = tesseract_cmd\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Replace with your fine-tuned model if available\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    print(\"[INFO] Converting PDF pages to images...\")\n",
    "    images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "    text = \"\"\n",
    "    for i, img in enumerate(images):\n",
    "        print(f\"[INFO] Running OCR on page {i+1}\")\n",
    "        text += pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    print(\"[INFO] Reading DOCX file...\")\n",
    "    doc = Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def load_keywords_from_folder(folder_path):\n",
    "    keywords = set()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") or filename.endswith(\".csv\"):\n",
    "            with open(os.path.join(folder_path, filename), encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    # Don't split on commas if you want multi-word phrases\n",
    "                    kw_clean = line.strip().lower()\n",
    "                    if kw_clean:\n",
    "                        keywords.add(kw_clean)\n",
    "    return list(keywords)\n",
    "\n",
    "def create_phrase_matcher(keywords, label):\n",
    "    matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "    patterns = [nlp.make_doc(text) for text in keywords]\n",
    "    matcher.add(label, patterns)\n",
    "    return matcher\n",
    "\n",
    "def extract_keywords_with_spacy(text, skills_keywords, titles_keywords):\n",
    "    doc = nlp(text)\n",
    "    skills_matcher = create_phrase_matcher(skills_keywords, \"SKILL\")\n",
    "    titles_matcher = create_phrase_matcher(titles_keywords, \"TITLE\")\n",
    "\n",
    "    skills_found = set()\n",
    "    titles_found = set()\n",
    "\n",
    "    # PhraseMatcher results\n",
    "    for match_id, start, end in skills_matcher(doc):\n",
    "        span = doc[start:end]\n",
    "        skills_found.add(span.text)\n",
    "\n",
    "    for match_id, start, end in titles_matcher(doc):\n",
    "        span = doc[start:end]\n",
    "        titles_found.add(span.text)\n",
    "\n",
    "    # NER results\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_.lower() in {\"skill\", \"job_title\", \"work_of_art\", \"org\", \"product\"}:\n",
    "            # Add additional logic if needed to separate skills from titles\n",
    "            if \"developer\" in ent.text.lower() or \"engineer\" in ent.text.lower():\n",
    "                titles_found.add(ent.text)\n",
    "            else:\n",
    "                skills_found.add(ent.text)\n",
    "\n",
    "    return list(skills_found), list(titles_found)\n",
    "\n",
    "def process_resume(file_path, skills_folder, titles_folder):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please use PDF or DOCX.\")\n",
    "\n",
    "    print(\"[INFO] Loading skills and job titles...\")\n",
    "    skills = load_keywords_from_folder(skills_folder)\n",
    "    titles = load_keywords_from_folder(titles_folder)\n",
    "\n",
    "    print(\"[INFO] Extracting skills and titles using spaCy...\")\n",
    "    found_skills, found_titles = extract_keywords_with_spacy(text, skills, titles)\n",
    "\n",
    "    print(\"\\n===== RESUME PARSE RESULT =====\")\n",
    "    print(\"Top 500 Characters of Extracted Text:\\n\", text[:500], \"\\n\")\n",
    "    print(\"Skills Found:\", found_skills)\n",
    "    print(\"Job Titles Found:\", found_titles)\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"skills\": found_skills,\n",
    "        \"titles\": found_titles\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"C:\\Users\\velam\\OneDrive\\Documents\\pavan's resume.docx\"\n",
    "    skills_folder = r\"C:\\amrita_uni\\Projects\\asmacs internship\\recognition of skills and title\\skills\"\n",
    "    titles_folder = r\"C:\\amrita_uni\\Projects\\asmacs internship\\recognition of skills and title\\titles\"\n",
    "    file_path2 = r\"C:\\amrita_uni\\Projects\\asmacs internship\\recognition of skills and title\\Imgdownload2.pdf\"\n",
    "    \n",
    "    result1 = process_resume(file_path, skills_folder, titles_folder)\n",
    "    result2 = process_resume(file_path2, skills_folder, titles_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
